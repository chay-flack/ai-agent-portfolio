## AI Lifecycle Governance & Control Framework

This repository contains a practical governance framework for authorising, commissioning,
and continuously controlling AI systems and automated workflows in regulated environments.

The framework is designed to ensure that AI-enabled systems operate within explicitly
approved boundaries, with clear accountability, defined authority, and ongoing assurance
as conditions change over time.

**Download the governance workbook:**  
[AI_Automation_Governance_Workbook.xlsx](AI_Automation_Governance_Workbook.xlsx)

---

## What this is

This artefact is a practical governance framework for AI systems, automation, and agents
operating in regulated, decision-critical environments.

It focuses on how AI-enabled systems are:
- intentionally designed
- explicitly authorised
- safely introduced into workflows
- governed before reliance begins

The framework emphasises operating model design and decision accountability rather than
technical implementation detail.

---

## Why this exists

In large institutions, governance failures in AI and automation rarely stem from:
- model performance
- algorithmic sophistication

They more commonly arise from:
- unclear ownership and decision rights
- poor workflow integration
- insufficient monitoring and escalation
- governance being applied after systems are already live

This framework introduces a **pre-flight governance check** to ensure systems are reviewed,
understood, and explicitly authorised before they are relied upon in practice.

---

## What “pre-flight” means

Pre-flight governance is a **design-time and go-live control** that asks:

- Where does this system sit in the end-to-end process?
- What decisions does it influence or support?
- What authority and autonomy is being granted?
- Who is accountable if outcomes deteriorate?
- Who has authority to pause or stop the system?

The objective is **decision integrity**, not compliance theatre.

---

## Relationship to AI operational specification (AI-OPS)

Pre-flight governance is performed **against an approved AI Operational Specification (AI-OPS)**.

AI-OPS defines:
- authorised behaviour and decision boundaries
- permitted data and system access
- acceptable outputs and tolerances
- escalation and failure expectations

Pre-flight checks validate that the system, configuration, and workflow are consistent
with the approved AI-OPS before operation begins.

---

## What’s included

The workbook contains two governance forms designed for different stages of maturity:

### Lite Governance Form
- Used for early experiments, prototypes, and local agents
- Proportional governance aligned to low reliance
- Fast to complete
- Encourages safe exploration without unnecessary friction

### Full Governance Form
- Used for systems approaching production or broader adoption
- Explicitly anchored to end-to-end workflows
- Clear ownership, escalation, and control points
- Suitable for regulated and decision-critical environments

---

## How it’s used in practice

1. Define or reference an AI-OPS for the system  
2. Select the Lite or Full form based on maturity and reliance  
3. Complete the form at design time, before development or deployment  
4. Review as part of a pre-flight approval process  
5. Use outputs to anchor monitoring, oversight, and change management  
6. Re-run pre-flight when scope, autonomy, or operating conditions change  

---

## Positioning

This framework reflects a focus on **AI governance, operating models, and senior decision-making**
in complex, regulated environments.

It is representative of how I approach:
- AI risk and control design
- accountability and decision rights
- governance that works in real institutions